import numpy as npimport sysimport osimport mathimport cv2from open3d import *predict_dir = "C:/Users/Pnagaraj/Lidar/dataset/training/velodyne/"image_dir = "C:/Users/Pnagaraj/Lidar/dataset/training/image_2/"lidar_dir = "C:/Users/Pnagaraj/Lidar/dataset/training/"calib_dir = "C:/Users/Pnagaraj/Lidar/dataset/training/calib/"trajectory_dir = "C:/Users/Pnagaraj/Lidar/dataset/training/camera_trajectory"#predict_dir = "/home/kangning/Documents/Masterarbeit/frustum-pointnets/train/detection_results_v1/data/"#image_dir = "/home/kangning/Documents/Masterarbeit/frustum-pointnets/dataset/KITTI/object/training/image_2/"#lidar_dir = "/home/kangning/Documents/Masterarbeit/frustum-pointnets/dataset/KITTI/object/training/velodyne/"#calib_dir = "/home/kangning/Documents/Masterarbeit/frustum-pointnets/dataset/KITTI/object/training/calib/"#lidar_image_dir = "/home/kangning/PycharmProjects/visualization/new_image/"#trajectory_dir = "/home/kangning/PycharmProjects/visualization/camera_trajectory/"height = 850width = 1700roi_height = 20roi_width = 40def read_label(label_path,index):    eval_dics = {}    eval_dics [index] = []    Bbox_dicts = {}    f = open(label_path, 'r')    lines = []    for line in f.readlines():        lines.append(line)    for line in lines:  ####for each object in each txt file        Bbox_dict =  {}        bbox2des = []        bbox2des_center = []        centers_list = []        size_list = []        rotation_y_list = []        parameter_list = line.strip().split(" ")        class_id = parameter_list[0]        xmin = np.asarray(parameter_list[4] ,dtype = 'float32') # xmin        ymin = np.asarray(parameter_list[5] ,dtype = 'float32')  # ymin        xmax = np.asarray(parameter_list[6] ,dtype = 'float32')  # xmax        ymax = np.asarray(parameter_list[7] ,dtype = 'float32') # ymax        box2d = np.array([xmin, ymin, xmax, ymax])        bbox2des.append(box2d)        box2d_center = np.array([(xmax - xmin) / 2, (ymax - ymin) / 2])        bbox2des_center.append(box2d_center)        height = parameter_list[8]        width = parameter_list[9]        length = parameter_list[10]        size = np.array([height, width, length])        size_list.append(size)  ## h,l,w of Bbox        tx = float(parameter_list[11])        ty = float(parameter_list[12])        tz = float(parameter_list[13])        center_list = np.array([tx, ty, tz])  # need to rotation along y    -rotation_y        centers_list.append(center_list)  # 3d center in camera coordinates??????        rotation_y = parameter_list[-2]        score = parameter_list[-1]        rotation_y_list.append(rotation_y)        predict_3d_center= provider.rotate_pc_along_y(-rotation_y)        Bbox_dict["center"] = center_list        Bbox_dict["height"] = float(height)        Bbox_dict["width"] = float(width)        Bbox_dict["length"] = float(length)        Bbox_dict["r_y"] = wrapToPi(float(rotation_y))        Bbox_dict["class_id"]= class_id        Bbox_dicts.update(Bbox_dict)        eval_dics[index].append(Bbox_dict)    return eval_dicsdef read_calib_file(calib_path):    out = dict()    for line in open(calib_path, 'r'):        line = line.strip()        if line == '' or line[0] == '#':            continue        val = line.split(':')        key_name = val[0].strip()        val = np.asarray(val[-1].strip().split(' '), dtype='f8')        if len(val) == 12:            out[key_name] = val.reshape(3, 4)        elif len(val) == 9:            out[key_name] = val.reshape(3, 3)    return outdef ScaleRows(z):    return int((height/2) + math.floor(z* (height / (2* roi_height))))   # Scaling z from 0 to 850def ScaleCols(x):    return int((width/2) + math.floor(x*(width / (2* roi_width))))   # Scaling x from 0 to 1700def ScaleY(y):    return math.floor((y +3) *25)predict_names = os.listdir(predict_dir)indexes = []for index,predict_name in enumerate(predict_names):    index = predict_name.split(".txt")[0]    sequence = predict_name.split(".bin")[0]    print("index",index)    print("sequence",sequence)    #print (index)    new_image = np.zeros((height,width,3),np.uint8)    #Change into white background    new_image[:,:,0].fill(255)    new_image[:,:,1].fill(255)    new_image[:,:,2].fill(255)    print(new_image)    indexes.append(sequence)    img_path = image_dir + sequence + ".png"    image = cv2.imread(img_path,-1)    lidar_path = predict_dir + sequence + ".bin"    print(lidar_path)    point_cloud = np.fromfile(lidar_path, dtype=np.float32).reshape(-1, 4)  # point cloud channel is x,y,z,reflectance    print(point_cloud.shape)    #### Remove points that locate behind camera    #point_cloud = point_cloud[point_cloud[:, 0] > -2.5, :]    # tr_velo_to_cam dot r0_rect    # using homogeneous transformation    calib_path = calib_dir + sequence + ".txt"    camera_trajectory = trajectory_dir + sequence + ".json"    calib = read_calib_file(calib_path)    P2 = calib['P2']    # print(P2)    # print(centers_list[0])    Tr_velo_to_cam_original = calib['Tr_velo_to_cam']    R0_rect_original = calib['R0_rect']    R0_rect = np.eye(4)    '''    array([[1., 0., 0., 0.],           [0., 1., 0., 0.],           [0., 0., 1., 0.],           [0., 0., 0., 1.]])    '''    R0_rect[0:3, 0:3] = R0_rect_original    Tr_velo_to_cam = np.eye(4)    Tr_velo_to_cam[0:3, :] = Tr_velo_to_cam_original    point_cloud_xyz = point_cloud[:, 0:3]    point_cloud_xyz_homo = np.ones((point_cloud.shape[0], 4))    point_cloud_xyz_homo[:, 0:3] = point_cloud[:, 0:3]    point_cloud_camera_non_rec = np.dot(Tr_velo_to_cam, point_cloud_xyz_homo.T)    point_cloud_camera_rect = np.dot(R0_rect, point_cloud_camera_non_rec).T  # 4 channels, homogeneous coordinates    # Homogeneous to cartesian: convert point_cloud_camera_rect(homogeneous coordinates into cartesian coordinates/point_cloud_xyz_camera )    point_cloud_xyz_camera = np.zeros((point_cloud_camera_rect.shape[0], 3))  # 3 channels , cartesian coordinates    point_cloud_xyz_camera[:, 0] = point_cloud_camera_rect[:, 0] / point_cloud_camera_rect[:, 3]    point_cloud_xyz_camera[:, 1] = point_cloud_camera_rect[:, 1] / point_cloud_camera_rect[:, 3]    point_cloud_xyz_camera[:, 2] = point_cloud_camera_rect[:, 2] / point_cloud_camera_rect[:, 3]    pcd = PointCloud()    pcd.points = Vector3dVector(point_cloud_xyz_camera)    #print(pcd.points[0])    for point in pcd.points:        z = point[0]        y = point[1]        x = point[2]        if math.fabs(z) <= roi_height and math.fabs(x) <= roi_width and y > -5 and y < 10:            #new_image[ScaleRows(z) , ScaleCols(x)] = [ScaleY(y),255, 255]            new_image[ScaleRows(z), ScaleCols(x)] = [205, 0, 0]    #new_image = cv2.cvtColor (new_image,cv2.COLOR_HSV2BGR)    test_path = "C:/Users/Pnagaraj/Lidar/dataset/training/top/"    if not os.path.exists(test_path):        os.makedirs(test_path)    print(type(new_image))    print(new_image.shape)    cv2.imwrite(test_path + sequence + ".png", new_image )